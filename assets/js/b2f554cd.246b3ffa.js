"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[1477],{10:e=>{e.exports=JSON.parse('{"blogPosts":[{"id":"google-search","metadata":{"permalink":"/blog/google-search","editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2023-01-21-How-Google-Search-Works/index.md","source":"@site/blog/2023-01-21-How-Google-Search-Works/index.md","title":"How Google\'s Search Works!","description":"How Google\'s Search Works!","date":"2023-01-21T00:00:00.000Z","formattedDate":"January 21, 2023","tags":[{"label":"google","permalink":"/blog/tags/google"},{"label":"search","permalink":"/blog/tags/search"}],"readingTime":1.3066666666666666,"hasTruncateMarker":false,"authors":[{"name":"Sai Mun Lee","title":"Software Engineer","url":"https://github.com/SaiMun92","imageURL":"https://github.com/SaiMun92.png","key":"saimun"}],"frontMatter":{"slug":"google-search","title":"How Google\'s Search Works!","authors":["saimun"],"tags":["google","search"]},"nextItem":{"title":"First Blog Post","permalink":"/blog/welcome"}},"content":"## How Google\'s Search Works!\\r\\nGoogle Search can be broken down into three steps namely:\\r\\n\\r\\n1. Crawling\\r\\n2. Indexing\\r\\n3. Searching\\r\\n\\r\\n#### Crawling\\r\\nCrawling is the process of searching the web for new and updated content.\\r\\nDuring crawling, _**Google**_ must constantly look for new and updated pages and add them to its list of\\r\\nknown pages. This process is called \\"URL discovery\\". \\r\\nThe program that does the fetching is called Googlebot (AKA Spiders) to crawl pages to extract out information and store it in an index. \\r\\nSuch information includes storing the addresses (or page URLs). Google also discovers other pages when you submit a \\r\\nlist of pages (a [sitemap](https://developers.google.com/search/docs/crawling-indexing/sitemaps/overview)) for Google to crawl.\\r\\nA sitemap is a file where you provide information about the pages, videos, and other files on your\\r\\nsite and the relationship between them. Information like video runtime, rating, age-appropriateness\\r\\nrating. It can also include the article title and publication date. \\r\\n\\r\\nHowever, _**Googlebot**_ doesn\'t crawl all the pages it discovered. Some issues that prevent Googlebot\\r\\nfrom accessing sites include:\\r\\n- Problems with the server handling the site\\r\\n- Network issues\\r\\n- robots.txt directives preventing Googlebot\'s access to the page.\\r\\n\\r\\n#### Indexing\\r\\nIndexing is the process of Google trying to understand what the page is about. It includes processing\\r\\nand analyzing the text content and key content tags and attributes, such as `<title>` elements,\\r\\nother attributes, images, videos and more. Google determines if a page is a duplicate of another page\\r\\non the internet. If there is, Google will select one and that will be the canonical version of the page.\\r\\nCanonical pages are the pages that Google will show in search results and which Google thinks its the most\\r\\nrepresented page of all the duplicates. Google also collects signals or metadata such as the language of\\r\\nthe page, the country the content is local to, the usability of the page and so on. All the collected information\\r\\nis stored on the Google Index, a large database hosted on thousands of computers.\\r\\n\\r\\n\\r\\n#### Searching\\r\\nSearching search the index and it ranks the results based on the search query. However,\\r\\nthe ranking algorithm is dependant of several factors such as language used, location of \\r\\nthe user and the search query to return the most relevant search results back to the user.\\r\\n\\r\\n\\r\\n### Summary\\r\\n![Gooogle Search Summary](./google-search.jpg)\\r\\n\\r\\n\\r\\n**Notes**\\r\\n- https://developers.google.com/search/docs/fundamentals/how-search-works\\r\\n- https://support.google.com/webmasters/answer/9128586?hl=en#:~:text=Crawling%3A%20Google%20searches%20the,that%20we%20already%20know%20about."},{"id":"welcome","metadata":{"permalink":"/blog/welcome","editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2023-01-18-First-blog-post/index.md","source":"@site/blog/2023-01-18-First-blog-post/index.md","title":"First Blog Post","description":"This is my first blog post!","date":"2023-01-18T00:00:00.000Z","formattedDate":"January 18, 2023","tags":[{"label":"hello","permalink":"/blog/tags/hello"}],"readingTime":0.08333333333333333,"hasTruncateMarker":false,"authors":[{"name":"Sai Mun Lee","title":"Software Engineer","url":"https://github.com/SaiMun92","imageURL":"https://github.com/SaiMun92.png","key":"saimun"}],"frontMatter":{"slug":"welcome","title":"First Blog Post","authors":["saimun"],"tags":["hello"]},"prevItem":{"title":"How Google\'s Search Works!","permalink":"/blog/google-search"}},"content":"This is my first blog post!\\r\\nThis whole blog is powered by Docusaurus - \\r\\n[Docusaurus blogging features](https://docusaurus.io/docs/blog) are powered by the [blog plugin](https://docusaurus.io/docs/api/plugins/@docusaurus/plugin-content-blog).\\r\\n![Docusaurus Plushie](./docusaurus-plushie-banner.jpeg)"}]}')}}]);